RAG (Retrieval-Augmented Generation) System
A production-ready Retrieval-Augmented Generation (RAG) system with multi-format document support, speech input/output, and dual LLM support (local + remote fallback).

This project was developed as a CSE445 course project, satisfying the requirement for:

Local Knowledge Base + RAG Pipeline + Local LLM + Remote LLM Fallback

ğŸ“‹ Table of Contents
 â€¢ Overview
 â€¢ Features
 â€¢ System Requirements
 â€¢ Installation Guide
    â€¢ Windows Setup
    â€¢ macOS Setup
 â€¢ Getting Started
 â€¢ Usage
 â€¢ Project Structure
 â€¢ Configuration
 â€¢ Working with Git
 â€¢ Development Workflow
 â€¢ Troubleshooting
 â€¢ Contributing Guidelines

ğŸ“Œ Overview
 â€¢ This project implements a Retrieval-Augmented Generation (RAG) system that:
 â€¢ Loads and processes documents from multiple formats
 â€¢ Converts documents into semantic embeddings using FAISS
 â€¢ Retrieves relevant context for user queries
 â€¢ Generates accurate answers using LLMs
 â€¢ Supports speech-to-text and text-to-speech
 â€¢ Automatically switches between local and remote LLMs
 â€¢ The system is designed to be modular, extensible, and production-ready.

 âœ¨ Features
ğŸ“„ Document Processing
 â€¢ Supports PDF, DOCX, PPTX, XLSX, CSV, TXT, HTML, Markdown, JSON
 â€¢ Image OCR support
 â€¢ Recursive chunking with configurable size and overlap
 â€¢ Metadata tracking for source attribution

ğŸ” Vector Search
 â€¢ FAISS vector database
 â€¢ 384-dimensional embeddings
 â€¢ SentenceTransformer (all-MiniLM-L6-v2)
 â€¢ Persistent local index storage

ğŸ¤– LLM Integration
 â€¢ Groq API (remote LLM fallback)
 â€¢ Ollama (local LLM for offline usage)
 â€¢ Automatic fallback mechanism
 â€¢ Configurable models

 ğŸ”§ System Requirements
Minimum
 â€¢ Python: 3.13.2+
 â€¢ RAM: 4 GB (8 GB recommended)
 â€¢ Storage: ~2 GB
 â€¢ Internet: Required for initial setup and Groq API
Optional (Local LLM)
 â€¢ Ollama
 â€¢ Additional 4â€“8 GB storage

ğŸ¤ Speech Capabilities
Speech-to-Text: OpenAI Whisper
Text-to-Speech: pyttsx3
Cross-platform support
ğŸ–¥ Interactive Interface
Menu-driven CLI
Text and voice query modes
Real-time progress and status output

ğŸ“¥ Installation Guide
Clone Repository
In bash
git clone https://github.com/rkrakib11/RAG.git
cd RAG

ğŸªŸ Windows Setup
Install uv
Download from: https://github.com/astral-sh/uv/releases

Verify:
In bash
uv --version

Install Dependencies:
In bash
uv sync
.\.venv\Scripts\activate

Environment Variables:
Create .env:

In bash
GROQ_API_KEY=your_groq_api_key
OPENAI_API_KEY=your_openai_api_key  # optional

Run
In bash
python main.py

ğŸ macOS Setup
Install uv
brew install uv

Install Dependencies
uv sync
source .venv/bin/activate

Optional: Local LLM
brew install ollama
ollama pull mistral
ollama serve

Run
python main.py

ğŸš€ Getting Started
python main.py


Commands:
 â€¢ t â†’ Text query
 â€¢ s â†’ Speech query
 â€¢ rebuild â†’ Rebuild FAISS index
 â€¢ exit â†’ Quit

ğŸ“– Usage:
Text Query Example:
Enter your question: What is machine learning?

Speech Query:
 â€¢ Speak after beep
 â€¢ System transcribes, retrieves context, answers, and speaks back

ğŸ“ Project Structure:
WRAPPER---CSE445/
â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ app.cpython-313.pyc
â”‚   â””â”€â”€ asr.cpython-313.pyc
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.cpython-313.pyc
â”‚   â”‚   â”œâ”€â”€ data_loader.cpython-313.pyc
â”‚   â”‚   â”œâ”€â”€ document_rag.cpython-313.pyc
â”‚   â”‚   â”œâ”€â”€ embedding.cpython-313.pyc
â”‚   â”‚   â”œâ”€â”€ local_llm.cpython-313.pyc
â”‚   â”‚   â”œâ”€â”€ search.cpython-313.pyc
â”‚   â”‚   â”œâ”€â”€ transcript_rag.cpython-313.pyc
â”‚   â”‚   â””â”€â”€ vectorstore.cpython-313.pyc
â”‚   â”‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py        # Load and preprocess documents
â”‚   â”œâ”€â”€ document_rag.py       # RAG pipeline for document-based queries
â”‚   â”œâ”€â”€ embedding.py          # Text chunking and embedding generation
â”‚   â”œâ”€â”€ local_llm.py          # Local LLM (Ollama) integration
â”‚   â”œâ”€â”€ search.py             # Semantic search logic
â”‚   â”œâ”€â”€ transcript_rag.py     # Speech-based RAG handling
â”‚   â””â”€â”€ vectorstore.py        # FAISS vector store management
â”‚
â”œâ”€â”€ app.py                    # Application-level logic
â”œâ”€â”€ asr.py                    # Speech-to-text (Whisper) handling
â”œâ”€â”€ main.py                   # Entry point (interactive CLI)
â”œâ”€â”€ LICENSE
â”œâ”€â”€ pyproject.toml            # Project configuration
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ uv.lock                   # Locked dependency versions

ğŸ‘¥ Contributing Guidelines
 â€¢ Follow PEP-8
 â€¢ Use meaningful commit messages
 â€¢ Never commit .env
 â€¢ Test before pushing
 
ğŸ“ Academic Information
 â€¢ Course: CSE445
 â€¢ Project Type: Final Project
 â€¢ Topic: Retrieval-Augmented Generation (RAG) And Local LLM And OpenAi

ğŸ“Œ Status
 â€¢ Python Version: 3.13.2+
 â€¢ Build: Stable
 â€¢ Deployment: Local
 â€¢ Last Updated: December 2025


 
